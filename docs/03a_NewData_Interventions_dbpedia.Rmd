---
title: "03a_DBpedia_Extract"
author: "J Andres Gannon"
date: "04/10/2020"

output:
  html_document:
    theme: flatly
    code_download: true
    toc: yes
  html_notebook:
    toc: yes
    toc_float: yes
editor_options:
  chunk_output_type: inline
---

```{r setup, include = FALSE}
library(magrittr)
library(ggplot2)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)
```

This document processes and cleans data manually entered from dbpedia using the wikipedia infoboxes.

# Load data
We load the googlesheet where the wikidata info for each US intervention was loaded.
```{r, warning = FALSE}
df <- googlesheets4::read_sheet(ss = "https://docs.google.com/spreadsheets/d/1wiiuNVE2Wt-ZWyZRWDoqyxvg-y-hWpNdDWwdZjYCvM4/edit#gid=1180615821",
                                    sheet = "03a_interventions_newdata_dbpedia",
                                    col_types = "ccnncccccccnnnnnnnnnnnc") # prevents nested lists in means columns
```

# Clean data
## Inspect
Check the data and see what fixes have to be made
```{r}
# Drop rows without wikidata ID
df <- df[!is.na(df$wikidata_id), ]
df_clean <- df

visdat::vis_dat(df)
naniar::gg_miss_var(df)

DT::datatable(funModeling::df_status(df))
```

# Potential drops
We've flagged some cases that may not qualify as interventions given the definition from IMI we are using "the movement of regular troops or forces (airborne, seaborne, shelling, etc) of one country inside another, in the context of some political issue or dispute"
```{r}
# Identify potential drops
df_drops <- subset(df, potential_drop == 1)
df_drops <- df_drops %>%
  dplyr::select(wikidata_name, wikidata_id, potential_drop, has_infobox, notes)
DT::datatable(df_drops)

# Drop potential drops
df$potential_drop[is.na(df$potential_drop)] <- 0
df <- df %>% dplyr::filter(df$potential_drop == 0)
```

# Dates
## Clean
Make sure dates are all properly formatted and convert to date type
```{r}
df$start_date <- as.Date(df$start_date, "%Y-%m-%d")
df$end_date <- as.Date(df$end_date, "%Y-%m-%d")
```

## Create new variables for duration of the intervention
```{r}
df$duration <- difftime(df$end_date, df$start_date, units = c("days"))

df %>%
    dplyr::select(wikidata_id, duration) %>%
    ggplot(aes(x = duration)) + 
    geom_histogram() + 
    labs(title = "Duration of US Interventions (1991-2020)", x = "Duration (Days)", y = "Number of Interventions") +
    theme_bw()

outliers::outlier(df$duration)

df %>%
    dplyr::select(wikidata_name, duration) %>%
    dplyr::filter(wikidata_name != 'Iraqiâ€“Kurdish conflict') %>%
    ggplot(aes(x = duration)) + 
    geom_histogram() + 
    labs(title = "Duration of US Interventions (1991-2020)", x = "Duration (Days)", y = "Number of Interventions", caption = "Iraqi-Kurdish conflict outlier excluded") +
    theme_bw()
```

The longest crisis by far is the Iraqi-Kurdish crisis since wikipedia lists its start date as 1918 and its end date as 2003.

# Locations
We have the locations as names and lat-lon

## Names
Should be able to pull the lat lon using google maps.
```{r}
locations <- df %>% dplyr::select(location_name) %>%
  dplyr::mutate(location_name = strsplit(as.character(location_name), ";")) %>%
  tidyr::unnest(location_name) %>%
  na.omit()
locations$location_name <- stringr::str_trim(locations$location_name)
locations <- locations %>% dplyr::distinct()
```

We get coordinates using the google cloud API and ggmap. Given daily download limit, we save the results as a csv to avoid having to rerun it
```{r, eval = FALSE}
library(ggmap)
mykey <- "AIzaSyAfKvl8754pRSsqRJgksUC9fOeq30bjda0"

register_google(key = mykey)

locations <- ggmap::mutate_geocode(locations, location_name, key = mykey)

write.csv(locations, paste0(here::here(), "/data/","locations.csv"))
```

```{r}
locations <- read.csv(paste0(here::here(), "/data/","locations.csv"))
locations$X <- NULL
```

## Lat lons
```{r}
# Split
df <- tidyr::separate(df, location_latlong, c('lat', 'lon'), sep = " ", remove = TRUE)

# Clean
df$lat <- parzer::parse_lat(df$lat)
df$lon <- parzer::parse_lon(df$lon)
```

## Merge
We now have coordinates from dbpedia as well as coordinates pulled from location names using the google maps API. We want those all in a single column
```{r}
# Rename in locations to prevent merge overwrite
df <- dplyr::left_join(df, locations, by = "location_name")

df <- df %>% dplyr::mutate(lat = dplyr::coalesce(lat.x, lat.y)) %>%
  dplyr::mutate(lon = dplyr::coalesce(lon.x, lon.y)) %>%
  dplyr::select(-c('lat.x', 'lat.y', 'lon.x', 'lon.y'))
```

## Plot
We can now visualize the location of each US intervention from 1991-2018 that exists in wikipedia. The pop up boxes display the name of the intervention as well as its start and end dates.

There are still some errors to parse, but it looks largely right.
```{r}
df_sf <- df %>% dplyr::filter(!is.na(lat)) %>%
  dplyr::filter(!is.na(lon))

## New column for means used
df_sf$means_aerialbombinglab[df_sf$means_aerialbombing == 1] <- "aerial bombing"
df_sf$means_airtoairlab[df_sf$means_airtoair == 1] <- "air to air"
df_sf$means_closeairsupportlab[df_sf$means_closeairsupport == 1] <- "close air support"
df_sf$means_cruisemissileslab[df_sf$means_cruisemissiles == 1] <- "cruise missiles"
df_sf$means_droneslab[df_sf$means_drones == 1] <- "drone strikes"
df_sf$means_groundtroopslab[df_sf$means_groundtroops == 1] <- "ground troops"
df_sf$means_paramilitarylab[df_sf$means_paramilitary == 1] <- "paramilitary"

df_sf$meanslab <- paste0(df_sf$means_aerialbombinglab, ", ", 
                         df_sf$means_airtoairlab, ", ", 
                         df_sf$means_closeairsupportlab, ", ", 
                         df_sf$means_cruisemissileslab, ", ", 
                         df_sf$means_droneslab, ", ", 
                         df_sf$means_groundtroopslab, ", ", 
                         df_sf$means_paramilitarylab)

# Delete NA and ", ," and padding
df_sf$meanslab <- gsub("NA, ", "", df_sf$meanslab)
df_sf$meanslab <- gsub(", NA", "", df_sf$meanslab)

# Create pop up label
## Pop up formatting
sep <- "<br>"
close_sep <- "</br>"
str_open <- "<strong>"
str_close <- "</strong>"

## Create label column
df_sf$label <- paste0(sep, str_open, "Intervention: ", str_close, df_sf$wikidata_name, close_sep, 
                      sep, str_open, "Dates: ", str_close, df_sf$start_date, " to ", df_sf$end_date, close_sep,
                      sep, str_open, "Location: ", str_close, df_sf$location_name, close_sep,
                      sep, str_open, "Target: ", str_close, df_sf$belligerent_sideB, close_sep,
                      sep, str_open, "Means: ", str_close, df_sf$meanslab, close_sep,
                      sep, str_open, "Result: ", str_close, df_sf$result, close_sep)

# Coerce to sf object
df_sf <- sf::st_as_sf(df_sf, coords = c("lon", "lat"))

# Calculate center for view
center_lon <- mean(df$lon, na.rm = TRUE)
center_lat <- mean(df$lat, na.rm = TRUE)

# Plot with leaflet
leaflet::leaflet() %>%
  leaflet::addTiles() %>%
  leaflet::addCircleMarkers(data = df_sf, popup = df_sf$label, clusterOptions = leaflet::markerClusterOptions()) %>%
  leaflet::setView(center_lon, center_lat, zoom = 3)
```


# Results
My gut is the results will be too complicated to tell anything from.
```{r}
tail(sort(unique(df$result)))
```

Actually, there is some consistency. We may be able to fuzzy string match or do some training based on terms like victory, unclear, tactical, strategic, failure, indecisive, etc. Project for later.

# Belligerents
## Split and gather
We want to confirm the US appears in these cases. But it has multiple string values. Can gather by semi-colon delimiters
```{r}
# sideA
df$belligerent_sideA <- stringi::stri_replace_all_fixed(df$belligerent_sideA, "(", ";")
df$belligerent_sideA <- stringi::stri_replace_all_fixed(df$belligerent_sideA, ")", "")

df <- df %>% 
  dplyr::mutate(belligerent_sideA = strsplit(as.character(belligerent_sideA), ";")) %>%
  tidyr::unnest(belligerent_sideA) %>%
  dplyr::mutate(belligerent_sideA = strsplit(as.character(belligerent_sideA), ",")) %>%
  tidyr::unnest(belligerent_sideA)

df$belligerent_sideA <- stringr::str_trim(df$belligerent_sideA)

sidea <- length(unique(df$belligerent_sideA))

# sideB
df$belligerent_sideB <- stringi::stri_replace_all_fixed(df$belligerent_sideB, "(", ";")
df$belligerent_sideB <- stringi::stri_replace_all_fixed(df$belligerent_sideB, ")", "")

df <- df %>% 
  dplyr::mutate(belligerent_sideB = strsplit(as.character(belligerent_sideB), ";")) %>%
  tidyr::unnest(belligerent_sideB) %>%
  dplyr::mutate(belligerent_sideB = strsplit(as.character(belligerent_sideB), ",")) %>%
  tidyr::unnest(belligerent_sideB)

df$belligerent_sideB <- stringr::str_trim(df$belligerent_sideB)

sideb <- length(unique(df$belligerent_sideB))
```

There are `r sidea` participants that have fought alongside the US and `r sideb` that have been on the opposing side of the US.

## Combine and ID
Combine all belligerents into a single list to see which we can match with ccodes and which we already have matched from wikidata.

Note that the countrycode matching needs to be cleaned since it's a fuzzy string matcher, so "Coalition Forces in Iraq" is given the country code for Iraq, which is incorrect.
```{r}
# Combine both sides into a single df
sidea <- as.data.frame(unique(df$belligerent_sideA)) %>%
  dplyr::rename(belligerent = "unique(df$belligerent_sideA)")
sideb <- as.data.frame(unique(df$belligerent_sideB)) %>%
    dplyr::rename(belligerent = "unique(df$belligerent_sideB)")

belligerent <- dplyr::full_join(sidea, sideb) %>%
  dplyr::distinct()

# Match with ccodes
belligerent$ccode <- countrycode::countrycode(belligerent$belligerent, 'country.name', 'cown')
belligerent$cname <- countrycode::countrycode(belligerent$ccode, 'cown', 'country.name')
```

Confirm that the lists match
```{r}
bellig_sheet <- googlesheets4::read_sheet(ss = "https://docs.google.com/spreadsheets/d/1wiiuNVE2Wt-ZWyZRWDoqyxvg-y-hWpNdDWwdZjYCvM4/edit#gid=1180615821",
                                    sheet = "belligerent_list")

belligerent <- belligerent %>% dplyr::select(belligerent)

extra <- dplyr::anti_join(bellig_sheet, belligerent)
extra <- nrow(extra)

missing <- dplyr::anti_join(belligerent, bellig_sheet)
missing <- nrow(missing)
```

There are `r extra` entities in the belligerent list that are not in the dbpedia sheet and `r missing` entities in the dbpedia sheet that are not in the belligerent list.

## Run SPARQL query
We can extract information on each belligerent from wikidata automatically using a SPARQL query. Since the query times out after 60 seconds, we have to loop through each one individually. The first entity, Ivory Coast, runs in roughly 42 seconds.
```{r, eval = FALSE}
library(SPARQL)

# Create list of all entities we need to query
entities <- c("Q1008", "Q1009", "Q1016", "Q1016", "Q1020", "Q1025", "Q1028", "Q1029", "Q1032", "Q1033", "Q1036", "Q1037", "Q1041", "Q1042", "Q1045", "Q1049", "Q10566647", "Q1065", "Q1076058", "Q1076058", "Q1076058", "Q1076058", "Q108462", "Q10861236", "Q10861236", "Q1112438", "Q11196", "Q11196", "Q11196", "Q114", "Q1142173", "Q115", "Q1153941", "Q115473", "Q1168497", "Q1168497", "Q117", "Q117907", "Q12207542", "Q1246", "Q12525579", "Q1274468", "Q1282507", "Q1316", "Q13257444", "Q13438898", "Q1349604", "Q1416238", "Q142", "Q1422667", "Q1424473", "Q145", "Q1459585", "Q1459585", "Q146720", "Q1477220", "Q148", "Q148", "Q149805", "Q149832", "Q15020959", "Q15020959", "Q15081016", "Q15180", "Q152220", "Q155654", "Q155654", "Q15611742", "Q15611742", "Q15646812", "Q15646812", "Q15704024", "Q15704024", "Q15709731", "Q15709731", "Q15709731", "Q159", "Q159", "Q159087", "Q15980911", "Q16", "Q16049541", "Q16147042", "Q16148530", "Q16199562", "Q16199562", "Q16243030", "Q1636183", "Q1641888", "Q1644886", "Q1644886", "Q16525650", "Q1672351", "Q1672366", "Q1674120", "Q1674121", "Q1674170", "Q1674170", "Q1674170", "Q1674170", "Q1679059", "Q1679059", "Q16849914", "Q16849914", "Q16849914", "Q16955169", "Q17", "Q17004199", "Q17006617", "Q170245", "Q170245", "Q17053094", "Q1740122", "Q17443556", "Q17443556", "Q17502017", "Q1766415", "Q1778229", "Q1788421", "Q17899406", "Q17984585", "Q17984585", "Q179933", "Q1806585", "Q180688", "Q18112628", "Q18112628", "Q18122635", "Q18122635", "Q18155793", "Q18206631", "Q18206631", "Q18210320", "Q183", "Q18392177", "Q18395275", "Q184", "Q18412532", "Q18651204", "Q18651204", "Q18651204", "Q18702437", "Q18702437", "Q18711585", "Q18712599", "Q18715205", "Q1878844", "Q1878844", "Q1878844", "Q1878844", "Q1878844", "Q1878844", "Q1878844", "Q188559", "Q189", "Q189946", "Q191", "Q192262", "Q193366", "Q193366", "Q19428976", "Q19429040", "Q19429054", "Q19610107", "Q19610107", "Q19691801", "Q19824111", "Q19824111", "Q19824111", "Q19824111", "Q19883290", "Q199841", "Q20", "Q2000803", "Q20050674", "Q20382097", "Q20382097", "Q20387047", "Q205047", "Q205047", "Q20635401", "Q20642762", "Q21070584", "Q21070585", "Q21070585", "Q21070585", "Q21070585", "Q21070585", "Q21070586", "Q21096224", "Q211", "Q21180296", "Q211853", "Q211853", "Q212", "Q212372", "Q212372", "Q212372", "Q213", "Q214", "Q21469695", "Q21481802", "Q215", "Q21503656", "Q217", "Q21723343", "Q218", "Q219", "Q219060", "Q221", "Q22120970", "Q222", "Q22264396", "Q224", "Q225", "Q225", "Q227", "Q228", "Q229", "Q22947425", "Q2298600", "Q2298600", "Q230", "Q23072467", "Q23072467", "Q232", "Q2320255", "Q233", "Q23334", "Q23427", "Q2357272", "Q236", "Q23681", "Q23943452", "Q24043381", "Q2409661", "Q241", "Q2420193", "Q2420193", "Q2420193", "Q2420193", "Q2429253", "Q2429253", "Q2429253", "Q2429253", "Q2429253", "Q2429253", "Q2429253", "Q2429253", "Q244165", "Q2475082", "Q24910076", "Q24910076", "Q24910076", "Q252", "Q258", "Q25932091", "Q262", "Q26244385", "Q2631403", "Q2631489", "Q2635866", "Q2635866", "Q2635966", "Q2635966", "Q2635966", "Q265", "Q26683", "Q27", "Q271110", "Q271110", "Q2746169", "Q277036", "Q28", "Q28001515", "Q28162759", "Q28540613", "Q286627", "Q286627", "Q2866334", "Q28877411", "Q28877411", "Q29", "Q29025613", "Q29025613", "Q29025613", "Q29025768", "Q29025768", "Q291419", "Q298", "Q2993709", "Q2993709", "Q2994636", "Q2994636", "Q29999", "Q30", "Q30", "Q30001872", "Q30021272", "Q3024068", "Q3024068", "Q3024068", "Q3024068", "Q30314807", "Q30324434", "Q3042087", "Q3043382", "Q3068744", "Q3076828", "Q309368", "Q309368", "Q309998", "Q309998", "Q309998", "Q31", "Q310147", "Q3108185", "Q3108185", "Q311381", "Q311841", "Q311841", "Q3135107", "Q3135107", "Q3186738", "Q32", "Q3242242", "Q32748", "Q32748", "Q3275050", "Q32835", "Q3294374", "Q33", "Q3300434", "Q332065", "Q334", "Q334731", "Q334731", "Q335361", "Q337233", "Q337233", "Q3394187", "Q3394187", "Q33946", "Q34", "Q3408639", "Q3408639", "Q343124", "Q34490", "Q34490", "Q34490", "Q34490", "Q34490", "Q3469483", "Q347", "Q34754", "Q35", "Q36", "Q3644630", "Q36597284", "Q36704", "Q37", "Q37024", "Q3707111", "Q38", "Q383108", "Q38799", "Q39", "Q398", "Q399", "Q40", "Q40362", "Q408", "Q41", "Q41053", "Q4119382", "Q4120437", "Q414", "Q419", "Q423", "Q424", "Q42418", "Q42418", "Q42418", "Q42418", "Q42418", "Q427941", "Q42899049", "Q43", "Q45", "Q4560880", "Q4560880", "Q458", "Q4669205", "Q4703056", "Q4770517", "Q4770518", "Q4770519", "Q4770521", "Q4770527", "Q4794345", "Q4794345", "Q485112", "Q48549870", "Q48549870", "Q4920321", "Q5015574", "Q5015574", "Q506245", "Q506245", "Q5118", "Q5137892", "Q5187", "Q52117655", "Q5219", "Q5237", "Q5267", "Q53081261", "Q5328", "Q5440239", "Q54873796", "Q5499887", "Q550108", "Q5638369", "Q5644124", "Q5644124", "Q56701444", "Q568900", "Q568912", "Q568912", "Q568912", "Q568914", "Q574", "Q58826", "Q59569823", "Q6082480", "Q6110167", "Q6123015", "Q6127176", "Q6130720", "Q6176532", "Q6192463", "Q619829", "Q619829", "Q619829", "Q6250", "Q636947", "Q636947", "Q6445784", "Q64611", "Q6493224", "Q657", "Q658247", "Q664", "Q664743", "Q668", "Q677505", "Q677505", "Q678", "Q67918859", "Q690419", "Q690419", "Q690419", "Q6930781", "Q6933310", "Q6934093", "Q711", "Q712", "Q7159", "Q717", "Q7184", "Q718723", "Q7210193", "Q721306", "Q7249786", "Q7249786", "Q7249786", "Q7294660", "Q7307438", "Q733", "Q736955", "Q737040", "Q739", "Q7568575", "Q7574579", "Q7574579", "Q7644811", "Q7644811", "Q7663194", "Q7663228", "Q7684199", "Q7760381", "Q781221", "Q781221", "Q783", "Q785078", "Q786", "Q787623", "Q787623", "Q79", "Q790", "Q792", "Q794", "Q796", "Q796", "Q796", "Q796", "Q798210", "Q801", "Q804", "Q805", "Q805", "Q810", "Q811", "Q813", "Q817", "Q819", "Q822", "Q826", "Q83286", "Q833", "Q836", "Q837", "Q838261", "Q842", "Q843", "Q846", "Q849180", "Q851", "Q852258", "Q854", "Q8568", "Q8568", "Q858", "Q858", "Q858", "Q858", "Q858819", "Q860943", "Q861979", "Q863", "Q865", "Q869", "Q874", "Q878", "Q878", "Q881", "Q884", "Q884", "Q889", "Q889", "Q8963018", "Q8963018", "Q8963018", "Q8963018", "Q897614", "Q897614", "Q902", "Q907112", "Q912", "Q921", "Q9212", "Q927467", "Q928", "Q928", "Q928", "Q929", "Q932728", "Q932728", "Q932728", "Q940293", "Q945", "Q946770", "Q948", "Q954", "Q958", "Q96", "Q962", "Q963", "Q965", "Q967", "Q972587", "Q973179", "Q973179", "Q973179", "Q974", "Q974", "Q977", "Q986")

# Set wikidata endpoint

endpoint <- "https://query.wikidata.org/sparql"

# Write query of columns we want returned for each entity
query <- 'SELECT 
  ?item ?itemLabel ?itemDescription 
  ?alias
  ?allegianceLabel
  ?applies_to_jurisdictionLabel
  ?area
  ?basic_form_of_governmentLabel
  ?commanded_byLabel
  ?conflictLabel
  ?contains_administrative_territorial_entityLabel
  ?countryLabel
  ?coordinate_location
  ?different_fromLabel
  ?dissolved__abolished_or_demolished
  ?elevation_above_sea_level
  ?ethnic_groupLabel
  ?flag_image
  ?followsLabel
  ?followed_byLabel
  ?has_partLabel
  ?has_qualityLabel
  ?headquarters_locationLabel
  ?inception
  ?instance_ofLabel
  ?located_in_or_next_to_body_of_waterLabel
  ?located_in_the_administrative_territorial_entityLabel
  ?located_on_terrain_featureLabel
  ?locationLabel
  ?location_of_formationLabel
  ?logo_image
  ?member_count
  ?member_of_political_partyLabel
  ?military_branchLabel
  ?native_label
  ?part_ofLabel
  ?participantLabel
  ?political_alignmentLabel
  ?political_ideologyLabel
  ?population
  ?religionLabel
  ?replacesLabel
  ?shares_border_withLabel
  ?subsidiaryLabel
  ?start_time
  ?territory_claimed_byLabel

WHERE {
  VALUES ?item {
  wd:Q1008
  }
  
  OPTIONAL {?item wdt:P945 ?allegiance. }
  OPTIONAL { ?item wdt:P1001 ?applies_to_jurisdiction. }
  OPTIONAL { ?item wdt:P2046 ?area. }
  OPTIONAL { ?item wdt:P122 ?basic_form_of_government. }
  OPTIONAL { ?item wdt:P4791 ?commanded_by. }
  OPTIONAL { ?item wdt:P607 ?conflict. }
  OPTIONAL { ?item wdt:P150 ?contains_administrative_territorial_entity. }
  OPTIONAL { ?item wdt:P17 ?country. }
  OPTIONAL { ?item wdt:P625 ?coordinate_location. }
  OPTIONAL { ?item wdt:P1889 ?different_from. }
  OPTIONAL { ?item wdt:P576 ?dissolved__abolished_or_demolished. }
  OPTIONAL { ?item wdt:P2044 ?elevation_above_sea_level. }
  OPTIONAL { ?item wdt:P172 ?ethnic_group. }
  OPTIONAL { ?item wdt:P41 ?flag_image. }
  OPTIONAL { ?item wdt:P155 ?follows. }
  OPTIONAL { ?item wdt:P156 ?followed_by. }
  OPTIONAL { ?item wdt:P527 ?has_part. }
  OPTIONAL { ?item wdt:P1552 ?has_quality. }
  OPTIONAL { ?item wdt:P159 ?headquarters_location. }
  OPTIONAL { ?item wdt:P571 ?inception. }
  OPTIONAL { ?item wdt:P31 ?instance_of. }
  OPTIONAL { ?item wdt:P206 ?located_in_or_next_to_body_of_water. }
  OPTIONAL { ?item wdt:P131 ?located_in_the_administrative_territorial_entity. }
  OPTIONAL { ?item wdt:P706 ?located_on_terrain_feature. }
  OPTIONAL { ?item wdt:P276 ?location. }
  OPTIONAL { ?item wdt:P740 ?location_of_formation. }\
  OPTIONAL { ?item wdt:P154 ?logo_image. }
  OPTIONAL { ?item wdt:P2124 ?member_count. }
  OPTIONAL { ?item wdt:P102 ?member_of_political_party. }
  OPTIONAL { ?item wdt:P241 ?military_branch. }
  OPTIONAL { ?item wdt:P1705 ?native_label. }
  OPTIONAL { ?item wdt:P361 ?part_of. }
  OPTIONAL { ?item wdt:P710 ?participant. }
  OPTIONAL { ?item wdt:P1387 ?political_alignment. }
  OPTIONAL { ?item wdt:P1142 ?political_ideology. }
  OPTIONAL { ?item wdt:P1082 ?population. }
  OPTIONAL { ?item wdt:P140 ?religion. }
  OPTIONAL { ?item wdt:P1365 ?replaces. }
  OPTIONAL { ?item wdt:P47 ?shares_border_with. }
  OPTIONAL { ?item wdt:P355 ?subsidiary. }
  OPTIONAL { ?item wdt:P580 ?start_time. }
  OPTIONAL { ?item wdt:P1336 ?territory_claimed_by. }
  OPTIONAL {
    ?item skos:altLabel ?alias.
    FILTER((LANG(?alias)) = "en")
  }
SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
}
LIMIT 10000'

# Set human name for useragent so it's not flagged as a bot for repeated queries
useragent <- paste("Andres Gannon", R.version.string, "jagannon@ucsd.edu")

# Run SPARQL query
qd <- SPARQL::SPARQL(endpoint, query, curl_args = list(useragent = useragent))

# Extract results into df
df <- qd$results

```

# Means
## Prep
Prep the means data by subsetting to just the DV variables and renaming them for easier human readings
```{r}
dv <- df_clean %>% dplyr::select(dplyr::starts_with("means_"))
dv <- as.data.frame(sapply(dv, as.numeric))
dv[is.na(dv)] <- 0

dv <- dv %>% dplyr::rename("Aerial bombing" = means_aerialbombing, "Air-to-air" = means_airtoair, "Close Air Support" = means_closeairsupport, "Cruise missiles" = means_cruisemissiles, "Drones" = means_drones, "Ground troops" = means_groundtroops, "Paramilitary" = means_paramilitary)
```

## Table
```{r}
counts <- df_clean %>% dplyr::select("wikidata_name", dplyr::starts_with("means_")) %>%
  tidyr::gather(wikidata_name, means) %>%
  dplyr::count(wikidata_name, means) %>%
  dplyr::filter(means == 1) %>%
  dplyr::select(-means)

DT::datatable(counts)
```

## Plot
```{r}
ggplot(counts, aes(x = wikidata_name, y = n)) + 
  geom_bar(stat = "identity") +
  labs(title = "Means of US Interventions (1991-2019)", x = "Means", y = "Event Count") +
  geom_text(aes(label = n), vjust = -0.5, size = 6) +
  theme_bw() +
  lims(y = c(0, 250)) +
  scale_x_discrete(labels = c("means_aerialbombing" = "Aerial bombing", "means_airtoair" = "Air-to-air", "means_closeairsupport" = "Close Air Support", "means_cruisemissiles" = "Cruise missiles", "means_drones" = "Drones", "means_groundtroops" = "Ground troops", "means_paramilitary" = "Paramilitary")) +
  theme(plot.title = element_text(),panel.grid = element_blank(),
        text = element_text(size = 16),
        axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

ggsave(paste0(here::here(),"/paper/figures/summary_stats/means_counts.png"), height = 8, width = 16, units = "in")
```

## Visualize combos
```{r, fig.width = 16, fig.height = 16}
UpSetR::upset(dv,
      number.angles = 0, point.size = 3, line.size = 1, text.scale = 2,
      mainbar.y.label = "Number of Interventions", order.by = "freq", set_size.show = TRUE, set_size.scale_max = 250)

upsetjs::upsetjs() %>%
  upsetjs::fromDataFrame(dv) %>%
  upsetjs::interactiveChart()
```

# Casualties
Compare casualties counts by side and specific to the US when that information is available
```{r}
df_clean %>%
    dplyr::select(wikidata_id, casualties_sideA) %>%
    ggplot(aes(x = casualties_sideA)) + 
    geom_histogram() + 
    labs(title = "Casualties during US Interventions - US and Allies (1991-2020)", x = "Number of Casualties", y = "Number of Interventions") +
    theme_bw()

df_clean %>%
    dplyr::select(wikidata_id, casualties_sideB) %>%
    ggplot(aes(x = casualties_sideB)) + 
    geom_histogram() + 
    labs(title = "Casualties during US Interventions - US Adversaries (1991-2020)", x = "Number of Casualties", y = "Number of Interventions") +
    theme_bw()

df_clean %>%
    dplyr::select(wikidata_id, casualties_civilian) %>%
    ggplot(aes(x = casualties_civilian)) + 
    geom_histogram() + 
    labs(title = "Casualties during US Interventions - Civilians (1991-2020)", x = "Number of Casualties", y = "Number of Interventions") +
    theme_bw()

df_clean %>%
    dplyr::select(wikidata_id, casualties_us) %>%
    ggplot(aes(x = casualties_us)) + 
    geom_histogram() + 
    labs(title = "Casualties during US Interventions - US (1991-2020)", x = "Number of Casualties", y = "Number of Interventions") +
    theme_bw()
```

# Save final data
```{r}
# Save
write.csv(df, paste0(here::here(), "/data/","03a_intervention_newdata_dbpedia.csv"))
```

# System info
```{r}
Sys.info()
```